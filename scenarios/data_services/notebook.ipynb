{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eb106b7",
   "metadata": {},
   "source": [
    "# Data Services for demo script\n",
    "See more examples of using data services on the link: https://github.com/th2-net/th2-data-services-template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c1f9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from IPython.core.display import display, HTML\n",
    "from datetime import datetime, timedelta\n",
    "from th2_data_services.data_source import DataSource\n",
    "from th2_data_services.data import Data\n",
    "from th2_data_services.events_tree import EventsTree\n",
    "from th2_data_services.utils import Utils\n",
    "from pandas import DataFrame, Grouper\n",
    "import pickle\n",
    "\n",
    "# This settings for increase display jupyter notebook and dataframe table.\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "pd.options.display.max_rows = 1500\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "# For understand which event type on based name we get from stream.\n",
    "def get_super_type(record, tree):\n",
    "    name = record.get(\"eventName\")\n",
    "    parent_id = record.get(\"parentEventId\")\n",
    "    super_type = record.get(\"eventType\")\n",
    "    if super_type == \"\":\n",
    "        if \"Recon\" in name:\n",
    "            super_type = \"Recon Folder\"\n",
    "        else:\n",
    "            if not parent_id:\n",
    "                super_type = \"Test Run\"\n",
    "            else:\n",
    "                parent_event = tree.get(parent_id)\n",
    "                if parent_event:\n",
    "                    parent_super_type = get_super_type(parent_event, tree)\n",
    "                    if parent_super_type == \"Test Run\":\n",
    "                        super_type = \"Test Case\"\n",
    "                    elif parent_super_type == \"Recon Folder\":\n",
    "                        super_type = \"Recon Rule\"\n",
    "                    elif parent_super_type == \"Recon Rule\":\n",
    "                        super_type = \"Recon Status\"\n",
    "                    elif parent_super_type == \"Recon Status\":\n",
    "                        super_type = \"Recon Event\"\n",
    "\n",
    "    return super_type\n",
    "\n",
    "# Base extract (transform function)\n",
    "# record is required arguments.\n",
    "def extract_basic(record):\n",
    "    new_object = {}\n",
    "    start_time = datetime.fromtimestamp(record.get(\"startTimestamp\", {}).get(\"epochSecond\", 0))\n",
    "    start_time += timedelta(microseconds=record.get(\"startTimestamp\", {}).get(\"nano\", 0))\n",
    "    end_time = datetime.fromtimestamp(record.get(\"endTimestamp\", {}).get(\"epochSecond\", 0))\n",
    "    end_time += timedelta(microseconds=record.get(\"endTimestamp\", {}).get(\"nano\", 0))\n",
    "    new_object.update(\n",
    "        {\n",
    "            \"super_type\": get_super_type(record, tree),\n",
    "            \"start_time\": start_time,\n",
    "            \"end_time\": end_time,\n",
    "            \"status\": \"SUCCESSFUL\" if record.get(\"successful\") else \"FAILED\",\n",
    "            \"eventName\": record.get(\"eventName\"),\n",
    "            \"eventId\": record.get(\"eventId\"),\n",
    "            \"parentEventId\": record.get(\"parentEventId\"),\n",
    "            \"body\": record.get(\"body\"),\n",
    "            \"messages_id\": record.get(\"attachedMessageIds\")\n",
    "        }\n",
    "    )\n",
    "    if new_object['eventName'] is None:\n",
    "        pprint(record)\n",
    "    return new_object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cfe3d0",
   "metadata": {},
   "source": [
    "## Start and finish test time setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35612fda",
   "metadata": {},
   "source": [
    "Get start and finish test time automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5831ae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open('start_datetime.pickle', 'rb') as f:\n",
    "    START_TIME = pickle.load(f)\n",
    "with open('finish_datetime.pickle', 'rb') as f:\n",
    "    END_TIME = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ec209a",
   "metadata": {},
   "source": [
    "You can also set the time manually.  \n",
    "Just uncomment the following code block and set the time of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a0bc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START_TIME = datetime(year=2021, month=6, day=20, hour=13, minute=44, second=41, microsecond=692724)\n",
    "# END_TIME = datetime(year=2021, month=6, day=20, hour=13, minute=45, second=49, microsecond=28579)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9511636",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PROVIDER_NODE_PORT = 30789\n",
    "HOST = '10.64.66.66'  # th2-kube-demo\n",
    "URL = F\"http://{HOST}:{DATA_PROVIDER_NODE_PORT}\"\n",
    "\n",
    "\n",
    "data_source = DataSource(URL)\n",
    "events_with_attached_msgs: Data = data_source.get_events_from_data_provider(\n",
    "    startTimestamp=START_TIME,\n",
    "    endTimestamp=END_TIME,\n",
    "    metadataOnly=False,\n",
    "    attachedMessages=True,\n",
    "    cache=True\n",
    ")\n",
    "    \n",
    "# We build events tree for further assistance.\n",
    "events_tree = EventsTree(events_with_attached_msgs)\n",
    "tree = events_tree.events\n",
    "\n",
    "# Here we get events which doesn't exist in data source interval.\n",
    "events_tree.recover_unknown_events(data_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8b6141",
   "metadata": {},
   "source": [
    "### Number of Events in the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5171318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acddf600",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Utils.aggregate_a_group(events_with_attached_msgs.map(extract_basic), \"super_type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01320c49",
   "metadata": {},
   "source": [
    "## Recons analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3827dc2",
   "metadata": {},
   "source": [
    "### [1] Summarize table\n",
    "The table summarizes the work of the check2-recon th2 component.  \n",
    "Shows the names of the rules, statuses, and how many there were."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d50b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_output(record):\n",
    "    recon_status = tree.get(record.get(\"parentEventId\"))\n",
    "    recon_rule = tree.get(recon_status.get(\"parentEventId\"))\n",
    "    recon_folder = tree.get(recon_rule.get(\"parentEventId\"))\n",
    "    new_obj = {\n",
    "        \"Recon Folder\": recon_folder.get(\"eventName\"),\n",
    "        \"Recon Rule\" : recon_rule.get(\"eventName\"),\n",
    "        \"Recon Status\": recon_status.get(\"eventName\"),\n",
    "        \"Number of Events\": 1,\n",
    "        \"Start Time\": record.get(\"start_time\"),\n",
    "        \"End Time\": record.get(\"end_time\")\n",
    "    }\n",
    "    return new_obj\n",
    "\n",
    "data: Data = events_with_attached_msgs\\\n",
    "        .map(extract_basic)\\\n",
    "        .filter(lambda record: record.get(\"super_type\") == \"Recon Event\")\\\n",
    "        .map(transform_output)\\\n",
    "\n",
    "# Functions from pandas.\n",
    "df = DataFrame(data).groupby(['Recon Folder', \"Recon Rule\", 'Recon Status']).agg(\n",
    "    {\"Number of Events\": \"sum\", \"Start Time\": \"min\", \"End Time\": \"max\"})\n",
    "\n",
    "df = Utils.append_total_rows(df, {\"Number of Events\": \"sum\", \"Start Time\": \"min\", \"End Time\": \"max\"})\n",
    "df[\"duration\"] = df[\"End Time\"] - df[\"Start Time\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da350cec",
   "metadata": {},
   "source": [
    "### [2] Table - Types of messages and their number processed by recon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f1e790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_recon_ancestor(record):\n",
    "    parent_id = record.get(\"parentEventId\")\n",
    "    if parent_id is not None:\n",
    "        ancestor = events_tree.get_ancestor_by_super_type(record, \"Recon Folder\", get_super_type)\n",
    "        if ancestor:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_match_or_match_failed(record):\n",
    "    ancestor = events_tree.get_ancestor_by_name(record, \"No match\")\n",
    "    if ancestor and not ancestor.get(\"successful\"):\n",
    "        return True\n",
    "    ancestor = events_tree.get_ancestor_by_name(record, \"Matched passed\")\n",
    "    if ancestor:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def exctract_block(record):\n",
    "    messages_id = record.get(\"messages_id\")\n",
    "    \n",
    "    if not messages_id:\n",
    "        return None\n",
    "        \n",
    "    messages = data_source.find_messages_by_id_from_data_provider(messages_id)\n",
    "    output = [{\"MsgType\": message.get(\"body\", {}).get(\"metadata\", {}).get(\"messageType\")} for message in messages]\n",
    "    \n",
    "    return output\n",
    "\n",
    "data = events_with_attached_msgs\\\n",
    "        .map(extract_basic)\\\n",
    "        .filter(is_recon_ancestor)\\\n",
    "        .filter(is_match_or_match_failed)\\\n",
    "        .map(exctract_block)\n",
    "\n",
    "df = DataFrame(data)\n",
    "df\n",
    "df.groupby(\"MsgType\").size().reset_index(name=\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4abb31d",
   "metadata": {},
   "source": [
    "## Script analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff5f846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_basic_script(record):\n",
    "    new_object = {}\n",
    "    start_time = datetime.fromtimestamp(record.get(\"startTimestamp\", {}).get(\"epochSecond\", 0))\n",
    "    start_time += timedelta(microseconds=record.get(\"startTimestamp\", {}).get(\"nano\", 0)/1000)\n",
    "    end_time = datetime.fromtimestamp(record.get(\"endTimestamp\", {}).get(\"epochSecond\", 0))\n",
    "    end_time += timedelta(microseconds=record.get(\"endTimestamp\", {}).get(\"nano\", 0)/1000)\n",
    "    new_object.update(\n",
    "        {\n",
    "            \"start_time\": start_time,\n",
    "            \"end_time\": end_time,\n",
    "            \"super_type\": get_super_type(record, tree),\n",
    "            \"eventName\": record.get(\"eventName\"),\n",
    "            \"parentEventId\": record.get(\"parentEventId\"),\n",
    "            \"status\": \"SUCCESSFUL\" if record.get(\"successful\") else \"FAILED\",\n",
    "            \"body\": record.get(\"body\"),\n",
    "            \"attachedMessageIds\": record.get(\"attachedMessageIds\")\n",
    "        }\n",
    "    )\n",
    "    return new_object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a95bc8",
   "metadata": {},
   "source": [
    "### [1] Basic statistics by test cases\n",
    "Shows how many test case are failed and are passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6517fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_output(record):    \n",
    "    new_obj = {\n",
    "        \"Test Case\": 1,\n",
    "        \"Status\": record.get(\"status\")\n",
    "    }\n",
    "    return new_obj\n",
    "\n",
    "data = events_with_attached_msgs\\\n",
    "        .map(extract_basic_script)\\\n",
    "        .filter(lambda record: record.get(\"super_type\") == \"Test Case\")\\\n",
    "        .map(transform_output)\n",
    "\n",
    "df = DataFrame(data=data)\n",
    "df = df.groupby([\"Status\"]).sum()\n",
    "df[\"Percent\"] = df[\"Test Case\"] / df[\"Test Case\"].sum() * 100\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e184b1a7",
   "metadata": {},
   "source": [
    "### [2] Detail statistics by test cases\n",
    "Shows each test cases name, status, time and duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a6131a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ancestor_is_test_case(record):\n",
    "    if not record.get(\"parentEventId\"):\n",
    "        return False\n",
    "    ancestor = events_tree.get_ancestor_by_super_type(record, \"Test Case\", get_super_type)\n",
    "    if ancestor:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def transform_output(record):\n",
    "    test_case = events_tree.get_ancestor_by_super_type(record, \"Test Case\", get_super_type)\n",
    "    test_run = tree.get(test_case.get(\"parentEventId\"))\n",
    "    \n",
    "    start_time = datetime.fromtimestamp(test_case.get(\"startTimestamp\", {}).get(\"epochSecond\", 0))\n",
    "    start_time += timedelta(microseconds=test_case.get(\"startTimestamp\", {}).get(\"nano\", 0)/1000)\n",
    "    \n",
    "    message_id = record.get(\"attachedMessageIds\")\n",
    "    \n",
    "    if not message_id:\n",
    "        return None\n",
    "    \n",
    "    message = next(data_source.find_messages_by_id_from_data_provider(message_id))\n",
    "    if not message:\n",
    "        return None\n",
    "    \n",
    "    body = message.get(\"body\", {})\n",
    "    if not body:\n",
    "        return None\n",
    "    \n",
    "    end_time = body.get(\"metadata\", {}).get(\"timestamp\")\n",
    "    end_time = datetime.strptime(end_time, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "    end_time += timedelta(hours=3)\n",
    "    \n",
    "    new_obj = {\n",
    "        \"Test Run\": test_run.get(\"eventName\"),\n",
    "        \"Test Case\": test_case.get(\"eventName\"),\n",
    "        \"Status\": \"SUCCESSFUL\" if test_case.get(\"successful\") else \"FAILED\",\n",
    "        'Start Time': start_time,\n",
    "        'End Time': end_time,\n",
    "    }\n",
    "    return new_obj\n",
    "\n",
    "data = events_with_attached_msgs\\\n",
    "        .map(extract_basic_script)\\\n",
    "        .filter(ancestor_is_test_case)\\\n",
    "        .filter(lambda record: record.get(\"super_type\") in [\"Verification\", \"message\"])\\\n",
    "        .map(transform_output)\n",
    "\n",
    "df = DataFrame(data=data)\n",
    "df = df.groupby([\"Test Run\", \"Test Case\", \"Status\"]).agg({\"Start Time\": \"min\", \"End Time\": \"max\"}).reset_index()\n",
    "df[\"duration\"] = df[\"End Time\"] - df[\"Start Time\"]\n",
    "df.sort_values(by=[\"Start Time\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30610bc3",
   "metadata": {},
   "source": [
    "### [3] Failed Verifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3f1566",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def is_test_case_ancestor(record):\n",
    "    parent_id = record.get(\"parentEventId\")\n",
    "    if parent_id is not None:\n",
    "        ancestor = events_tree.get_ancestor_by_super_type(record, \"Test Case\", get_super_type)\n",
    "        if ancestor:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def extract_failed_tags(record):\n",
    "    # .get(\"parentEventId\")\n",
    "    new_obj = {\n",
    "        \"Event Id\": record.get(\"eventId\"),\n",
    "        \"Event Name\": record.get(\"eventName\"),\n",
    "        \"Test Run\": events_tree.get_ancestor_by_super_type(record, \"Test Run\", get_super_type).get(\"eventName\"),\n",
    "        \"Test Case\": events_tree.get_ancestor_by_super_type(record, \"Test Case\", get_super_type).get(\"eventName\"),\n",
    "    }\n",
    "    tags = []\n",
    "    for content in record.get(\"body\"):\n",
    "        Utils.get_failed_tags(content, tags)\n",
    "    new_obj.update({\"tags\": tags})\n",
    "    return new_obj\n",
    "\n",
    "data = events_with_attached_msgs\\\n",
    "        .map(extract_basic)\\\n",
    "        .filter(is_test_case_ancestor)\\\n",
    "        .filter(lambda record: record.get(\"super_type\") == \"Verification\")\\\n",
    "        .filter(lambda record: record.get(\"status\") == \"FAILED\")\\\n",
    "        .map(extract_failed_tags)\n",
    "\n",
    "transform_data = []\n",
    "for i in data:\n",
    "    common = {\n",
    "        \"Event Name\": i.get(\"Event Name\"),\n",
    "        \"Test Run\": i.get(\"Test Run\"),\n",
    "        \"Test Case\": i.get(\"Test Case\"),\n",
    "        \"Event_Id\": i.get(\"Event Id\"),\n",
    "    }\n",
    "    for tag in i[\"tags\"]:\n",
    "        transform_data.append({**common, **tag})\n",
    "\n",
    "# From pandas for comforted view\n",
    "failed_verifications = DataFrame(data=transform_data)\n",
    "failed_verifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755ca88a",
   "metadata": {},
   "source": [
    "### [4] Plot all data aggregated by supertype into a single chart with filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0de3974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_calc(record: dict):\n",
    "    r = record.copy()\n",
    "    r['time'] = record['start_time']\n",
    "    return r\n",
    "        \n",
    "df = Utils.aggregate_a_group_by_intervals(events_with_attached_msgs.map(extract_basic).map(time_calc), \"super_type\", \"10s\", filter=[\"Recon Event\", \"Verification\"])\n",
    "\n",
    "Utils.create_tick_diagram(df)  # The plot may not be shown if you have not restarted the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c9f7c6",
   "metadata": {},
   "source": [
    "### [5] Latency density\n",
    "Searches pairs messages with type NewOrderSingle and ExecutionReport. Then calculates latency and demonstrates on plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57be723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_new_single_order_or_execution_report(record):\n",
    "    body = record.get(\"body\")\n",
    "    if body:\n",
    "        message_type = body.get(\"metadata\", {}).get(\"messageType\")\n",
    "        if message_type in [\"NewOrderSingle\", \"ExecutionReport\"]:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def clear_unnecessery_fields(record):\n",
    "    new_obj = None\n",
    "    body = record.get(\"body\")\n",
    "    if body:\n",
    "        fields = body.get(\"fields\", {})\n",
    "        clOrdID = fields.get(\"ClOrdID\", {}).get(\"simpleValue\")\n",
    "        ord_status = fields.get(\"OrdStatus\", {}).get(\"simpleValue\")\n",
    "        \n",
    "        metadata = body.get(\"metadata\", {})\n",
    "        message_type = metadata.get(\"messageType\")\n",
    "        session_alias = metadata.get(\"id\", {}).get(\"connectionId\", {}).get(\"sessionAlias\")\n",
    "        time = metadata.get(\"timestamp\")\n",
    "        \n",
    "        new_obj = {\n",
    "            \"clOrdID\": clOrdID,\n",
    "            \"OrdStatus\": ord_status,\n",
    "            \"MessageType\": message_type,\n",
    "            \"sessionAlias\": session_alias,\n",
    "            \"time\": time,\n",
    "        }\n",
    "    return new_obj\n",
    "\n",
    "streams = set()\n",
    "for record in events_tree.events.values():\n",
    "    messages = record.get(\"attachedMessageIds\")\n",
    "    for msg in messages:\n",
    "        streams.add(msg.split(\":\")[0])\n",
    "        \n",
    "messages = data_source.get_messages_from_data_provider(\n",
    "    startTimestamp=START_TIME,\n",
    "    endTimestamp=END_TIME,\n",
    "    stream=list(streams)\n",
    ")\n",
    "data = messages\\\n",
    "        .filter(is_new_single_order_or_execution_report)\\\n",
    "        .map(clear_unnecessery_fields)\n",
    "\n",
    "roundtrips = {}\n",
    "latency = []\n",
    "\n",
    "for record in data:\n",
    "    msg_type = record.get(\"MessageType\")\n",
    "    clOrdID = record.get(\"clOrdID\")\n",
    "    \n",
    "    if msg_type == \"NewOrderSingle\":\n",
    "        if clOrdID not in roundtrips:\n",
    "            roundtrips[clOrdID] = record.get(\"time\")\n",
    "    elif msg_type == \"ExecutionReport\":\n",
    "        if record.get(\"OrdStatus\") == '0':\n",
    "            if clOrdID in roundtrips:\n",
    "                current_latency = datetime.strptime(record.get(\"time\"), \"%Y-%m-%dT%H:%M:%S.%fZ\") -  datetime.strptime(roundtrips[clOrdID], \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "                latency.append({\"latency\": 1, \"time\": datetime.strptime(str(current_latency), \"%H:%M:%S.%f\")})\n",
    "\n",
    "df = DataFrame(data=latency).set_index(\"time\").groupby(Grouper(freq=\"10ms\")).sum()\n",
    "df.index = df.index.strftime(\"%S.%f\")\n",
    "\n",
    "Utils.create_tick_diagram(df)  # The plot may not be shown if you have not restarted the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fb3be9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
